{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14cdc1ac",
      "metadata": {
        "id": "14cdc1ac"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44ede702",
      "metadata": {
        "id": "44ede702",
        "outputId": "d682a8ce-1651-4c95-ee25-e391d8cae67c",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27915 entries, 0 to 27914\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  27915 non-null  int64 \n",
            " 1   text        27913 non-null  object\n",
            " 2   sentiment   27912 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 654.4+ KB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('tweets_v2.csv', delimiter=',')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2a2420e",
      "metadata": {
        "id": "e2a2420e",
        "outputId": "8d1f648e-f00e-4758-f2da-c3e157358731",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>27915.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13957.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8058.510718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6978.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13957.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>20935.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>27914.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Unnamed: 0\n",
              "count  27915.000000\n",
              "mean   13957.000000\n",
              "std     8058.510718\n",
              "min        0.000000\n",
              "25%     6978.500000\n",
              "50%    13957.000000\n",
              "75%    20935.500000\n",
              "max    27914.000000"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ce205a",
      "metadata": {
        "id": "05ce205a",
        "outputId": "3e6e13f1-8fc5-4644-9906-16edbe243842",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...</td>\n",
              "      <td>neu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA https://t...</td>\n",
              "      <td>neu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...</td>\n",
              "      <td>neu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Fla x cor quem ganha em?</td>\n",
              "      <td>neu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Desfalques do #Flamengo contra o Corinthians: ...</td>\n",
              "      <td>neu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text sentiment\n",
              "0           0  ‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...       neu\n",
              "1           1  ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA https://t...       neu\n",
              "2           2  Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...       neu\n",
              "3           3                           Fla x cor quem ganha em?       neu\n",
              "4           4  Desfalques do #Flamengo contra o Corinthians: ...       neu"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60902a8b",
      "metadata": {
        "id": "60902a8b"
      },
      "source": [
        "# Processamento dos textos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22dd686f",
      "metadata": {
        "id": "22dd686f"
      },
      "outputs": [],
      "source": [
        "def tweet_processing(tweets):\n",
        "    import re\n",
        "    from unidecode import unidecode\n",
        "    import string\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    \n",
        "    # removendo URLs\n",
        "    tweets['text_preproc'] = tweets['text'].apply(lambda x: re.sub(r\"http\\S+\", \"\", str(x)))\n",
        "    tweets['text_preproc'] = tweets['text_preproc'].apply(lambda x: re.sub('@[^\\s]+','',str(x)))\n",
        "    # transformando em min√∫sculo\n",
        "    tweets['text_preproc'] = tweets['text_preproc'].apply(lambda x: x.lower())\n",
        "    # removendo acentua√ß√£o\n",
        "    tweets['text_preproc'] = tweets['text_preproc'].apply(lambda x: unidecode(x))\n",
        "    # removendo caracteres de nova linha\n",
        "    tweets['text_preproc'] = tweets['text_preproc'].apply(lambda x: x.replace('\\r\\n',' '))\n",
        "    \n",
        "    tweets['text_preproc'] = tweets['text_preproc'].apply(lambda x: remove_stopwords(x))\n",
        "    \n",
        "    # removendo pontua√ß√£o dos tweets\n",
        "    tweets['text_preproc'] = tweets['text_preproc'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "    # stemming\n",
        "    tweets['text_preproc'] = tweets['text_preproc'].apply(lambda text: do_stem(text))\n",
        "    \n",
        "    # aplicando o tokenizer\n",
        "    tweets['tokens'] = tweets['text_preproc'].apply(word_tokenize)\n",
        "    return tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bda59fa",
      "metadata": {
        "id": "6bda59fa",
        "outputId": "e34cc482-387e-4d9b-ebbc-954a5a326dc8",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_preproc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...</td>\n",
              "      <td>neu</td>\n",
              "      <td>‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA https://t...</td>\n",
              "      <td>neu</td>\n",
              "      <td>ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...</td>\n",
              "      <td>neu</td>\n",
              "      <td>Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Fla x cor quem ganha em?</td>\n",
              "      <td>neu</td>\n",
              "      <td>Fla x cor quem ganha em?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Desfalques do #Flamengo contra o Corinthians: ...</td>\n",
              "      <td>neu</td>\n",
              "      <td>Desfalques do #Flamengo contra o Corinthians: ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text sentiment  \\\n",
              "0           0  ‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...       neu   \n",
              "1           1  ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA https://t...       neu   \n",
              "2           2  Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...       neu   \n",
              "3           3                           Fla x cor quem ganha em?       neu   \n",
              "4           4  Desfalques do #Flamengo contra o Corinthians: ...       neu   \n",
              "\n",
              "                                        text_preproc  \n",
              "0  ‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...  \n",
              "1              ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA   \n",
              "2  Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...  \n",
              "3                           Fla x cor quem ganha em?  \n",
              "4  Desfalques do #Flamengo contra o Corinthians: ...  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "tweets = df.copy()\n",
        "# removendo URLs\n",
        "tweets['text_preproc'] = tweets['text'].apply(lambda x: re.sub(r\"http\\S+\", \"\", str(x)))\n",
        "tweets['text_preproc'] = tweets['text_preproc'].apply(lambda x: re.sub('@[^\\s]+','',str(x)))\n",
        "tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73356e80",
      "metadata": {
        "id": "73356e80",
        "outputId": "2c1a5b3b-29be-4153-f940-714e31380480",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_preproc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...</td>\n",
              "      <td>neu</td>\n",
              "      <td>* copa do brasil * final (ida)\\n\\n corinthians...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA https://t...</td>\n",
              "      <td>neu</td>\n",
              "      <td>adorooo\\n#vamosflamengo \\n#corxfla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...</td>\n",
              "      <td>neu</td>\n",
              "      <td>boa noite nacao corintiana!\\n#corxfla \\n#prime...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Fla x cor quem ganha em?</td>\n",
              "      <td>neu</td>\n",
              "      <td>fla x cor quem ganha em?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Desfalques do #Flamengo contra o Corinthians: ...</td>\n",
              "      <td>neu</td>\n",
              "      <td>desfalques do #flamengo contra o corinthians: ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text sentiment  \\\n",
              "0           0  ‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...       neu   \n",
              "1           1  ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA https://t...       neu   \n",
              "2           2  Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...       neu   \n",
              "3           3                           Fla x cor quem ganha em?       neu   \n",
              "4           4  Desfalques do #Flamengo contra o Corinthians: ...       neu   \n",
              "\n",
              "                                        text_preproc  \n",
              "0  * copa do brasil * final (ida)\\n\\n corinthians...  \n",
              "1                adorooo\\n#vamosflamengo \\n#corxfla   \n",
              "2  boa noite nacao corintiana!\\n#corxfla \\n#prime...  \n",
              "3                           fla x cor quem ganha em?  \n",
              "4  desfalques do #flamengo contra o corinthians: ...  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from unidecode import unidecode\n",
        "\n",
        "# transformando em min√∫sculo\n",
        "tweets['text_preproc'] = tweets['text_preproc'].apply(lambda x: x.lower())\n",
        "# removendo acentua√ß√£o\n",
        "tweets['text_preproc'] = tweets['text_preproc'].apply(lambda x: unidecode(x))\n",
        "# removendo caracteres de nova linha\n",
        "tweets['text_preproc'] = tweets['text_preproc'].apply(lambda x: x.replace('\\r\\n',' '))\n",
        "tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b472711",
      "metadata": {
        "id": "2b472711"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "722026c8",
      "metadata": {
        "id": "722026c8"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text):\n",
        "    \n",
        "    # separando o texto em uma lista\n",
        "    words = text.split(' ')\n",
        "    \n",
        "    # coletando a lista de stopwords\n",
        "    stop_words = set(stopwords.words('portuguese')) \n",
        "\n",
        "    # filtrando o texto, removendo as stopwords\n",
        "    words_filtered = [w for w in words if w not in stop_words]\n",
        "    \n",
        "    # juntando a lista de palavras em texto novamente\n",
        "    text_filtered = ' '.join(words_filtered)\n",
        "    \n",
        "    return text_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "750327af",
      "metadata": {
        "id": "750327af",
        "outputId": "a59ea44f-81c1-4788-e00b-ea00637de01e",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_preproc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...</td>\n",
              "      <td>neu</td>\n",
              "      <td>* copa brasil * final (ida)\\n\\n corinthians x ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA https://t...</td>\n",
              "      <td>neu</td>\n",
              "      <td>adorooo\\n#vamosflamengo \\n#corxfla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...</td>\n",
              "      <td>neu</td>\n",
              "      <td>boa noite nacao corintiana!\\n#corxfla \\n#prime...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Fla x cor quem ganha em?</td>\n",
              "      <td>neu</td>\n",
              "      <td>fla x cor ganha em?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Desfalques do #Flamengo contra o Corinthians: ...</td>\n",
              "      <td>neu</td>\n",
              "      <td>desfalques #flamengo contra corinthians: bruno...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text sentiment  \\\n",
              "0           0  ‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...       neu   \n",
              "1           1  ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA https://t...       neu   \n",
              "2           2  Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...       neu   \n",
              "3           3                           Fla x cor quem ganha em?       neu   \n",
              "4           4  Desfalques do #Flamengo contra o Corinthians: ...       neu   \n",
              "\n",
              "                                        text_preproc  \n",
              "0  * copa brasil * final (ida)\\n\\n corinthians x ...  \n",
              "1                adorooo\\n#vamosflamengo \\n#corxfla   \n",
              "2  boa noite nacao corintiana!\\n#corxfla \\n#prime...  \n",
              "3                                fla x cor ganha em?  \n",
              "4  desfalques #flamengo contra corinthians: bruno...  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# removendo stopwords do nosso texto\n",
        "tweets['text_preproc'] = tweets['text_preproc'].apply(lambda x: remove_stopwords(x))\n",
        "tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f31c8614",
      "metadata": {
        "id": "f31c8614",
        "outputId": "3d2c52c2-a68c-461e-b9ce-c4e15c13512a",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_preproc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...</td>\n",
              "      <td>neu</td>\n",
              "      <td>copa brasil  final ida\\n\\n corinthians x flam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA https://t...</td>\n",
              "      <td>neu</td>\n",
              "      <td>adorooo\\nvamosflamengo \\ncorxfla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...</td>\n",
              "      <td>neu</td>\n",
              "      <td>boa noite nacao corintiana\\ncorxfla \\nprimevid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Fla x cor quem ganha em?</td>\n",
              "      <td>neu</td>\n",
              "      <td>fla x cor ganha em</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Desfalques do #Flamengo contra o Corinthians: ...</td>\n",
              "      <td>neu</td>\n",
              "      <td>desfalques flamengo contra corinthians bruno h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text sentiment  \\\n",
              "0           0  ‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...       neu   \n",
              "1           1  ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA https://t...       neu   \n",
              "2           2  Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...       neu   \n",
              "3           3                           Fla x cor quem ganha em?       neu   \n",
              "4           4  Desfalques do #Flamengo contra o Corinthians: ...       neu   \n",
              "\n",
              "                                        text_preproc  \n",
              "0   copa brasil  final ida\\n\\n corinthians x flam...  \n",
              "1                  adorooo\\nvamosflamengo \\ncorxfla   \n",
              "2  boa noite nacao corintiana\\ncorxfla \\nprimevid...  \n",
              "3                                 fla x cor ganha em  \n",
              "4  desfalques flamengo contra corinthians bruno h...  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import string\n",
        "\n",
        "# removendo pontua√ß√£o dos tweets\n",
        "tweets['text_preproc'] = tweets['text_preproc'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cc9076f",
      "metadata": {
        "id": "5cc9076f"
      },
      "outputs": [],
      "source": [
        "# tweets['sentiment'] = '-'\n",
        "# tweets.to_excel(\"tweets.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caa117b0",
      "metadata": {
        "id": "caa117b0"
      },
      "outputs": [],
      "source": [
        "#  fun√ß√£o para aplicar o stemming\n",
        "def do_stem(text):\n",
        "    \n",
        "    # separando o texto em uma lista de palavras\n",
        "    words = text.split(' ')\n",
        "    \n",
        "    stemmer = nltk.stem.RSLPStemmer()\n",
        "\n",
        "    # aplicando o stemming no texto\n",
        "    words_stem = [stemmer.stem(w) for w in words if len(w)>0]\n",
        "    \n",
        "    # juntando a lista de palavras em texto novamente\n",
        "    text_stem = ' '.join(words_stem)\n",
        "    \n",
        "    return text_stem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4226b29",
      "metadata": {
        "id": "c4226b29",
        "outputId": "ec789575-472b-48c9-cb27-369678603321",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_preproc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...</td>\n",
              "      <td>neu</td>\n",
              "      <td>cop brasil final ida\\n\\n corinth x flamengo\\n ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA https://t...</td>\n",
              "      <td>neu</td>\n",
              "      <td>adorooo\\nvamosflameng \\ncorxfl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...</td>\n",
              "      <td>neu</td>\n",
              "      <td>boa noit naca corintiana\\ncorxfl \\nprimevide \\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Fla x cor quem ganha em?</td>\n",
              "      <td>neu</td>\n",
              "      <td>fla x cor ganh em</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Desfalques do #Flamengo contra o Corinthians: ...</td>\n",
              "      <td>neu</td>\n",
              "      <td>desfalqu flameng contr corinth brun henriqu ro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text sentiment  \\\n",
              "0           0  ‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...       neu   \n",
              "1           1  ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA https://t...       neu   \n",
              "2           2  Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...       neu   \n",
              "3           3                           Fla x cor quem ganha em?       neu   \n",
              "4           4  Desfalques do #Flamengo contra o Corinthians: ...       neu   \n",
              "\n",
              "                                        text_preproc  \n",
              "0  cop brasil final ida\\n\\n corinth x flamengo\\n ...  \n",
              "1                     adorooo\\nvamosflameng \\ncorxfl  \n",
              "2  boa noit naca corintiana\\ncorxfl \\nprimevide \\...  \n",
              "3                                  fla x cor ganh em  \n",
              "4  desfalqu flameng contr corinth brun henriqu ro...  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets['text_preproc'] = tweets['text_preproc'].apply(lambda text: do_stem(text))\n",
        "tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fc21f6f",
      "metadata": {
        "id": "3fc21f6f",
        "outputId": "394e50b6-60e2-4403-f4ae-cfc1dc6a88fd",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_preproc</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...</td>\n",
              "      <td>neu</td>\n",
              "      <td>cop brasil final ida\\n\\n corinth x flamengo\\n ...</td>\n",
              "      <td>[cop, brasil, final, ida, corinth, x, flamengo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA https://t...</td>\n",
              "      <td>neu</td>\n",
              "      <td>adorooo\\nvamosflameng \\ncorxfl</td>\n",
              "      <td>[adorooo, vamosflameng, corxfl]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...</td>\n",
              "      <td>neu</td>\n",
              "      <td>boa noit naca corintiana\\ncorxfl \\nprimevide \\...</td>\n",
              "      <td>[boa, noit, naca, corintiana, corxfl, primevid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Fla x cor quem ganha em?</td>\n",
              "      <td>neu</td>\n",
              "      <td>fla x cor ganh em</td>\n",
              "      <td>[fla, x, cor, ganh, em]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Desfalques do #Flamengo contra o Corinthians: ...</td>\n",
              "      <td>neu</td>\n",
              "      <td>desfalqu flameng contr corinth brun henriqu ro...</td>\n",
              "      <td>[desfalqu, flameng, contr, corinth, brun, henr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                               text sentiment  \\\n",
              "0           0  ‚Ä¢ COPA DO BRASIL ‚Ä¢ FINAL (IDA)\\n\\n‚öΩ Corinthian...       neu   \n",
              "1           1  ü•∞ adorooo\\n#VamosFlamengo \\n#CORxFLA https://t...       neu   \n",
              "2           2  Boa Noite Na√ß√£o Corintiana!\\n#CORxFLA \\n#Prime...       neu   \n",
              "3           3                           Fla x cor quem ganha em?       neu   \n",
              "4           4  Desfalques do #Flamengo contra o Corinthians: ...       neu   \n",
              "\n",
              "                                        text_preproc  \\\n",
              "0  cop brasil final ida\\n\\n corinth x flamengo\\n ...   \n",
              "1                     adorooo\\nvamosflameng \\ncorxfl   \n",
              "2  boa noit naca corintiana\\ncorxfl \\nprimevide \\...   \n",
              "3                                  fla x cor ganh em   \n",
              "4  desfalqu flameng contr corinth brun henriqu ro...   \n",
              "\n",
              "                                              tokens  \n",
              "0  [cop, brasil, final, ida, corinth, x, flamengo...  \n",
              "1                    [adorooo, vamosflameng, corxfl]  \n",
              "2  [boa, noit, naca, corintiana, corxfl, primevid...  \n",
              "3                            [fla, x, cor, ganh, em]  \n",
              "4  [desfalqu, flameng, contr, corinth, brun, henr...  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# aplicando o tokenizer\n",
        "tweets['tokens'] = tweets['text_preproc'].apply(word_tokenize)\n",
        "tweets.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53b545d6",
      "metadata": {
        "id": "53b545d6"
      },
      "source": [
        "# Separando os tweets base por sentimento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b04980fb",
      "metadata": {
        "id": "b04980fb"
      },
      "outputs": [],
      "source": [
        "def factorize_sentiment(sentiment):\n",
        "    if sentiment == 'neg':\n",
        "        return 0\n",
        "    if sentiment == 'neu':\n",
        "        return 1\n",
        "    if sentiment == 'pos':\n",
        "        return 2\n",
        "    return -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00e07f37",
      "metadata": {
        "id": "00e07f37"
      },
      "outputs": [],
      "source": [
        "tweets['sentiment_fact'] = tweets.sentiment.apply(lambda x : factorize_sentiment(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd9105b9",
      "metadata": {
        "id": "bd9105b9",
        "outputId": "115b0b01-e2a9-4565-d402-cad5c20ae3b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(272, 6)\n",
            "(396, 6)\n",
            "(527, 6)\n"
          ]
        }
      ],
      "source": [
        "tweets_pos = tweets[tweets.sentiment_fact == 2]\n",
        "tweets_neg = tweets[tweets.sentiment_fact == 0]\n",
        "tweets_neu = tweets[tweets.sentiment_fact == 1]\n",
        "print(tweets_pos.shape)\n",
        "print(tweets_neg.shape)\n",
        "print(tweets_neu.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bebccd93",
      "metadata": {
        "id": "bebccd93",
        "outputId": "b265f011-c5fb-4353-dfc9-3c9d5f458f00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(835, 2)\n",
            "(360, 2)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TRAIN_SIZE = 0.7\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "X_pos = tweets_pos[['text_preproc', 'tokens']]\n",
        "# X_pos = tweets_pos[['text_preproc']]\n",
        "# X_pos = tweets_pos[['tokens']]\n",
        "y_pos = tweets_pos[['sentiment_fact']]\n",
        "\n",
        "X_neg = tweets_neg[['text_preproc', 'tokens']]\n",
        "# X_neg = tweets_neg[['text_preproc']]\n",
        "# X_neg = tweets_neg[['tokens']]\n",
        "y_neg = tweets_neg[['sentiment_fact']]\n",
        "\n",
        "X_neu = tweets_neu[['text_preproc', 'tokens']]\n",
        "# X_neu = tweets_neu[['text_preproc']]\n",
        "# X_neu = tweets_neu[['tokens']]\n",
        "y_neu = tweets_neu[['sentiment_fact']]\n",
        "\n",
        "X_pos_train, X_pos_test, y_pos_train, y_pos_test = train_test_split(X_pos, y_pos, train_size=TRAIN_SIZE, random_state=RANDOM_STATE)\n",
        "X_neg_train, X_neg_test, y_neg_train, y_neg_test = train_test_split(X_neg, y_neg, train_size=TRAIN_SIZE, random_state=RANDOM_STATE)\n",
        "X_neu_train, X_neu_test, y_neu_train, y_neu_test = train_test_split(X_neu, y_neu, train_size=TRAIN_SIZE, random_state=RANDOM_STATE)\n",
        "\n",
        "# X_train = X_pos_train + X_neg_train + X_neu_train\n",
        "X_train = pd.concat([X_pos_train, X_neg_train, X_neu_train],axis=0)\n",
        "# X_test = X_pos_test + X_neg_test + X_neu_test\n",
        "X_test = pd.concat([X_pos_test, X_neg_test, X_neu_test], axis=0)\n",
        "# y_train = y_pos_train + y_neg_train + y_neu_train\n",
        "y_train = pd.concat([y_pos_train, y_neg_train, y_neu_train],axis=0)\n",
        "# y_test = y_pos_test + y_neg_test + y_neu_test\n",
        "y_test = pd.concat([y_pos_test, y_neg_test, y_neu_test],axis=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41b17410",
      "metadata": {
        "id": "41b17410"
      },
      "source": [
        "# Representa√ß√£o num√©rica"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "709dd693",
      "metadata": {
        "id": "709dd693"
      },
      "source": [
        "## Bag of words "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f851f9f2",
      "metadata": {
        "id": "f851f9f2"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "BoW = CountVectorizer()\n",
        "\n",
        "# treinando o modelo de vetoriza√ß√£o e transformando os dados de treino\n",
        "BoW_X_train = BoW.fit_transform(X_train['text_preproc']).toarray()\n",
        "\n",
        "# aplicando o modelo treinado aos dados de teste\n",
        "BoW_X_test  = BoW.transform(X_test['text_preproc']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b8880b6",
      "metadata": {
        "id": "2b8880b6",
        "outputId": "d3256f80-883b-487b-a4a3-263cf0ffad8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(360, 3364)\n"
          ]
        }
      ],
      "source": [
        "print(BoW_X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d05d441c",
      "metadata": {
        "id": "d05d441c",
        "outputId": "648ad560-d5f2-4555-b22f-96a8dfffec4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n"
          ]
        }
      ],
      "source": [
        "print(type(BoW))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13d663a9",
      "metadata": {
        "id": "13d663a9",
        "outputId": "60e03924-e0b7-4f00-82e6-240765653d7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(835, 3364)"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BoW_X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "184e1d7f",
      "metadata": {
        "id": "184e1d7f"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pkl_filename=\"bow.pkl\"\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(BoW, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ae4d6df",
      "metadata": {
        "id": "1ae4d6df"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pkl_filename=\"doc_train.pkl\"\n",
        "with open(pkl_filename, 'wb') as file:\n",
        "    pickle.dump(X_train['text_preproc'], file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87fcf96e",
      "metadata": {
        "id": "87fcf96e"
      },
      "source": [
        "## Term Frequency - Inverse Document Frequency (TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bed1dfb7",
      "metadata": {
        "id": "bed1dfb7"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "Tfidf = TfidfVectorizer()\n",
        "\n",
        "# treinando o modelo de vetoriza√ß√£o e transformando os dados de treino\n",
        "Tfidf_X_train = Tfidf.fit_transform(X_train['text_preproc']).toarray()\n",
        "\n",
        "# aplicando o modelo treinado aos dados teste\n",
        "Tfidf_X_test  = Tfidf.transform(X_test['text_preproc']).toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aded455",
      "metadata": {
        "id": "4aded455"
      },
      "source": [
        "## Word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f674cba4",
      "metadata": {
        "id": "f674cba4"
      },
      "source": [
        "### Continuous Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55c0386c",
      "metadata": {
        "id": "55c0386c"
      },
      "outputs": [],
      "source": [
        "# from https://www.geeksforgeeks.org/python-word-embedding-using-word2vec\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "# cbow_model = gensim.models.Word2Vec(X_test['text_preproc'], min_count = 1, vector_size = 50, window = 5)\n",
        "cbow_model = gensim.models.Word2Vec(X_test['tokens'], min_count = 1, vector_size = 50, window = 10)\n",
        "word2vec_cbow = cbow_model.wv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25830eca",
      "metadata": {
        "id": "25830eca"
      },
      "source": [
        "### Skip Gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c2b5046",
      "metadata": {
        "id": "5c2b5046"
      },
      "outputs": [],
      "source": [
        "# skipg_model = gensim.models.Word2Vec(X_test['text_preproc'], min_count = 1, vector_size = 50, window = 5, sg = 1)\n",
        "skipg_model = gensim.models.Word2Vec(X_test['tokens'], min_count = 1, vector_size = 50, window = 10, sg = 1)\n",
        "word2vec_skipg = skipg_model.wv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58810f4c",
      "metadata": {
        "id": "58810f4c"
      },
      "outputs": [],
      "source": [
        "def get_average_word2vec(tokens_list, vector, generate_missing=False, k=50):\n",
        "    if len(tokens_list)<1:\n",
        "        return np.zeros(k)\n",
        "    if generate_missing:\n",
        "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
        "    else:\n",
        "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
        "    length = len(vectorized)\n",
        "    summed = np.sum(vectorized, axis=0)\n",
        "    averaged = np.divide(summed, length)\n",
        "    return averaged\n",
        "\n",
        "def get_word2vec_embeddings(vectors, clean_questions, generate_missing=False):\n",
        "    embeddings = clean_questions['tokens'].apply(lambda x: get_average_word2vec(x, vectors, \n",
        "                                                                                generate_missing=generate_missing))\n",
        "    return list(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08429b17",
      "metadata": {
        "id": "08429b17"
      },
      "outputs": [],
      "source": [
        "word2vec_cbow_X_train = get_word2vec_embeddings(word2vec_cbow, X_train)\n",
        "word2vec_cbow_X_test = get_word2vec_embeddings(word2vec_cbow, X_test)\n",
        "\n",
        "word2vec_skipg_X_train = get_word2vec_embeddings(word2vec_skipg, X_train)\n",
        "word2vec_skipg_X_test = get_word2vec_embeddings(word2vec_skipg, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e7373f0",
      "metadata": {
        "id": "7e7373f0"
      },
      "source": [
        "# Testando modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fad36590",
      "metadata": {
        "id": "fad36590"
      },
      "source": [
        "## NaiveBayes e BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55772e04",
      "metadata": {
        "id": "55772e04",
        "outputId": "d8f951e7-1e52-4bcd-c00e-91084d34b236",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6638888888888889\n",
            "[[ 87  18  14]\n",
            " [ 28 111  20]\n",
            " [ 20  21  41]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.73      0.69       119\n",
            "           1       0.74      0.70      0.72       159\n",
            "           2       0.55      0.50      0.52        82\n",
            "\n",
            "    accuracy                           0.66       360\n",
            "   macro avg       0.64      0.64      0.64       360\n",
            "weighted avg       0.66      0.66      0.66       360\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\andre\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "# importando as bibliotecas\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "\n",
        "# criando e treinando o modelo\n",
        "naive_bayes_classifier = MultinomialNB(alpha=1)\n",
        "naive_bayes_classifier.fit(BoW_X_train, y_train)\n",
        "\n",
        "# realizando a predi√ß√£o nos dados de teste\n",
        "y_pred = naive_bayes_classifier.predict(BoW_X_test)\n",
        "\n",
        "# finalmente, vamos ver os resultados do modelo\n",
        "score1 = metrics.accuracy_score(y_test, y_pred)\n",
        "print(score1)\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a97f097",
      "metadata": {
        "id": "1a97f097"
      },
      "outputs": [],
      "source": [
        "# naive_bayes_classifier.predict_proba(y_pred).round(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156d685b",
      "metadata": {
        "id": "156d685b"
      },
      "source": [
        "## NaiveBayes e TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "287898cf",
      "metadata": {
        "id": "287898cf",
        "outputId": "2b396c6e-4320-428c-e71d-0b41adad0e7d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6083333333333333\n",
            "[[ 70  48   1]\n",
            " [ 15 144   0]\n",
            " [ 14  63   5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.59      0.64       119\n",
            "           1       0.56      0.91      0.70       159\n",
            "           2       0.83      0.06      0.11        82\n",
            "\n",
            "    accuracy                           0.61       360\n",
            "   macro avg       0.70      0.52      0.48       360\n",
            "weighted avg       0.67      0.61      0.55       360\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\andre\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "naive_bayes_classifier = MultinomialNB(alpha=2)\n",
        "naive_bayes_classifier.fit(Tfidf_X_train, y_train)\n",
        "y_pred = naive_bayes_classifier.predict(Tfidf_X_test)\n",
        "\n",
        "score1 = metrics.accuracy_score(y_test, y_pred)\n",
        "print(score1)\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cacfcb39",
      "metadata": {
        "id": "cacfcb39"
      },
      "source": [
        "## SVC e BoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "844c04b9",
      "metadata": {
        "id": "844c04b9",
        "outputId": "0af08f60-2dc9-414d-fd50-2e0b1fdac941",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\andre\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.46944444444444444\n",
            "[[ 10 109   0]\n",
            " [  1 158   0]\n",
            " [  0  81   1]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.08      0.15       119\n",
            "           1       0.45      0.99      0.62       159\n",
            "           2       1.00      0.01      0.02        82\n",
            "\n",
            "    accuracy                           0.47       360\n",
            "   macro avg       0.79      0.36      0.27       360\n",
            "weighted avg       0.73      0.47      0.33       360\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_bow_classifier = SVC(kernel=\"poly\")\n",
        "svc_bow_classifier.fit(BoW_X_train, y_train)\n",
        "y_pred = svc_bow_classifier.predict(BoW_X_test)\n",
        "\n",
        "score1 = metrics.accuracy_score(y_test, y_pred)\n",
        "print(score1)\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbd485fe",
      "metadata": {
        "id": "cbd485fe"
      },
      "source": [
        "## SVC E TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e052836",
      "metadata": {
        "id": "0e052836",
        "outputId": "33a9c32e-9c65-42a9-b26f-0de73e6e525b",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\andre\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7027777777777777\n",
            "[[ 91  22   6]\n",
            " [ 17 130  12]\n",
            " [ 17  33  32]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.76      0.75       119\n",
            "           1       0.70      0.82      0.76       159\n",
            "           2       0.64      0.39      0.48        82\n",
            "\n",
            "    accuracy                           0.70       360\n",
            "   macro avg       0.69      0.66      0.66       360\n",
            "weighted avg       0.70      0.70      0.69       360\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_classifier = SVC(kernel=\"sigmoid\")\n",
        "svc_classifier.fit(Tfidf_X_train, y_train)\n",
        "y_pred = svc_classifier.predict(Tfidf_X_test)\n",
        "\n",
        "score1 = metrics.accuracy_score(y_test, y_pred)\n",
        "print(score1)\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23d4a1f9",
      "metadata": {
        "id": "23d4a1f9"
      },
      "outputs": [],
      "source": [
        "# import pickle\n",
        "\n",
        "# with open(\"svc_tfidf_sig.pkl\", 'wb') as file:\n",
        "#     pickle.dump(svc_classifier, file)\n",
        "# with open(\"tfidf.pkl\", 'wb') as file:\n",
        "#     pickle.dump(Tfidf, file)\n",
        "# with open(\"tfidf_train.pkl\", 'wb') as file:\n",
        "#     pickle.dump(X_train['text_preproc'], file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39e821de",
      "metadata": {
        "id": "39e821de"
      },
      "source": [
        "## SVC e Word2Vec CBoW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d39e084",
      "metadata": {
        "id": "7d39e084",
        "outputId": "1cd0bd66-9305-4dc6-9400-587468669ce4",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5916666666666667\n",
            "[[ 76  35   8]\n",
            " [ 29 125   5]\n",
            " [ 24  46  12]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.64      0.61       119\n",
            "           1       0.61      0.79      0.68       159\n",
            "           2       0.48      0.15      0.22        82\n",
            "\n",
            "    accuracy                           0.59       360\n",
            "   macro avg       0.56      0.52      0.51       360\n",
            "weighted avg       0.57      0.59      0.56       360\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\andre\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_classifier = SVC(kernel=\"rbf\")\n",
        "svc_classifier.fit(word2vec_cbow_X_train, y_train)\n",
        "y_pred = svc_classifier.predict(word2vec_cbow_X_test)\n",
        "\n",
        "score1 = metrics.accuracy_score(y_test, y_pred)\n",
        "print(score1)\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac64d7d",
      "metadata": {
        "id": "fac64d7d"
      },
      "source": [
        "## SVC e Word2Vec Skip Gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b05b544",
      "metadata": {
        "id": "1b05b544",
        "outputId": "ee0294ad-0d56-4230-b520-3fc4e3e4e839",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.44166666666666665\n",
            "[[  0 119   0]\n",
            " [  0 159   0]\n",
            " [  0  82   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       119\n",
            "           1       0.44      1.00      0.61       159\n",
            "           2       0.00      0.00      0.00        82\n",
            "\n",
            "    accuracy                           0.44       360\n",
            "   macro avg       0.15      0.33      0.20       360\n",
            "weighted avg       0.20      0.44      0.27       360\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\andre\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "C:\\Users\\andre\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\andre\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\andre\\anaconda3\\envs\\datascience\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_classifier = SVC()\n",
        "svc_classifier.fit(word2vec_skipg_X_train, y_train)\n",
        "y_pred = svc_classifier.predict(word2vec_skipg_X_test)\n",
        "\n",
        "score1 = metrics.accuracy_score(y_test, y_pred)\n",
        "print(score1)\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Julia 1.8.2",
      "language": "julia",
      "name": "julia-1.8"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
